"""
Israeli Pension Report Extractor
=================================
Extracts 5 structured tables from Hebrew pension PDFs using PyMuPDF + GPT-4o.

Tables extracted:
  table_a â€“ ×ª×©×œ×•××™× ×¦×¤×•×™×™×        (Expected payments)
  table_b â€“ ×ª× ×•×¢×•×ª ×‘×§×¨×Ÿ           (Account movements)
  table_c â€“ ×“××™ × ×™×”×•×œ ×•×”×•×¦××•×ª     (Management fees)
  table_d â€“ ××¡×œ×•×œ×™ ×”×©×§×¢×” ×•×ª×©×•××•×ª  (Investment tracks & returns)
  table_e â€“ ×¤×™×¨×•×˜ ×”×¤×§×“×•×ª          (Deposit details)
"""

import io
import json
import re
import math

import fitz          # PyMuPDF
import openai
import pandas as pd
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="×—×™×œ×•×¥ × ×ª×•× ×™ ×§×¨×Ÿ ×¤× ×¡×™×”",
    page_icon="ğŸ“Š",
    layout="wide",
)

st.title("ğŸ“Š ×—×™×œ×•×¥ × ×ª×•× ×™ ×§×¨×Ÿ ×¤× ×¡×™×” â€” Pension Report Extractor")
st.markdown(
    "Upload an Israeli pension PDF report (Migdal, Altshuler, Clal, Meitav, More). "
    "The app extracts 5 structured tables using PyMuPDF + GPT-4o."
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar â€“ API key & settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ Settings")
    st.markdown(
        "**Supported companies:**\n"
        "- ××’×“×œ Migdal\n- ××œ×˜×©×•×œ×¨ ×©×—× Altshuler Shaham\n"
        "- ×›×œ×œ Clal\n- ××™×˜×‘ Meitav\n- ××•×¨ More"
    )
    st.markdown("---")
    st.caption("v1.0 Â· Hebrew RTL-safe extraction")

# â”€â”€ Load API key from Streamlit Secrets â”€â”€
try:
    api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    st.error(
        "âš ï¸ OpenAI API key not found in Streamlit Secrets.\n\n"
        "Add it in your app settings under **Secrets** as:\n"
        "```\nOPENAI_API_KEY = \"sk-...\"\n```"
    )
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: extract all text from PDF
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_pdf_text(pdf_bytes: bytes) -> str:
    """Return concatenated text of every page using PyMuPDF."""
    pages_text = []
    try:
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page_num, page in enumerate(doc, start=1):
                text = page.get_text("text")          # plain text, preserves lines
                pages_text.append(f"=== PAGE {page_num} ===\n{text}")
    except Exception as exc:
        st.error(f"PyMuPDF error: {exc}")
        raise
    return "\n".join(pages_text)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: call GPT-4o for structured extraction
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """
You are a RAW TEXT TRANSCRIBER for Israeli pension fund reports (×§×¨×Ÿ ×¤× ×¡×™×”).
Your ONLY job is to locate five specific tables in the raw PDF text and return
their contents in a strict JSON format.

CRITICAL RULES:
1. ZERO interpretation, rounding, or calculation â€” copy numbers EXACTLY as they appear.
2. If a cell is empty or not found, use null (JSON null).
3. Negative numbers may appear with a trailing minus sign, an en-dash (â€“), or a
   leading minus. Keep them EXACTLY as extracted â€” do NOT normalise them.
4. Hebrew text direction causes column shifting in raw extraction â€” do your best
   to align values to the correct column headers using context clues.
5. Return ONLY valid JSON â€” no markdown fences, no commentary.

OUTPUT SCHEMA (return this exact structure):
{
  "table_a": [
    {"description": "<string>", "amount": "<string>"}
  ],
  "table_b": [
    {"description": "<string>", "amount": "<string>"}
  ],
  "table_c": [
    {"description": "<string>", "percentage": "<string>"}
  ],
  "table_d": [
    {"track_name": "<string>", "return_percentage": "<string>"}
  ],
  "table_e": [
    {
      "month": "<string>",
      "salary": "<string>",
      "employee": "<string>",
      "employer": "<string>",
      "severance": "<string>",
      "total": "<string>"
    }
  ]
}

TABLE IDENTIFICATION GUIDE:
- table_a â†’ ×ª×©×œ×•××™× ×¦×¤×•×™×™× (expected future payments, has description + NIS amount)
- table_b â†’ ×ª× ×•×¢×•×ª ×‘×§×¨×Ÿ / ×ª× ×•×¢×•×ª ×‘×—×©×‘×•×Ÿ (account movements: deposits, withdrawals, fees)
- table_c â†’ ×“××™ × ×™×”×•×œ / ×”×•×¦××•×ª (management fees as % of salary or savings)
- table_d â†’ ××¡×œ×•×œ ×”×©×§×¢×” / ×ª×©×•××” (investment tracks with % return) â€” SEE CRITICAL NOTES BELOW
- table_e â†’ ×¤×™×¨×•×˜ ×”×¤×§×“×•×ª / ×”×¤×§×“×•×ª ×—×•×“×©×™×•×ª (monthly deposit breakdown by component)

CRITICAL NOTES FOR table_d (×ª×©×•××•×ª â€” Return Percentages):
1. The section header is explicitly "×“. ××¡×œ×•×œ×™ ×”×©×§×¢×” ×•×ª×©×•××•×ª ×‘×ª×§×•×¤×ª ×”×“×•×—" or similar.
2. The return_percentage is the % figure that appears DIRECTLY next to the track name
   inside the ×“ section ONLY â€” never take values from section ×’ (×“××™ × ×™×”×•×œ).
3. The ONLY reliable way to distinguish between table_c and table_d values is by
   their SECTION HEADER â€” not by their size. Returns can be large (10%, 15%, 20%+).
4. LEGAL RULE YOU MUST USE: ×“××™ × ×™×”×•×œ ××—×™×¡×›×•×Ÿ (management fee from savings) is
   legally capped in Israel at 0.5% maximum. Any value above 0.5% CANNOT be a
   management fee from savings â€” but it CAN be an investment return.
5. DO NOT confuse section ×’ (×“××™ × ×™×”×•×œ) with section ×“ (×ª×©×•××•×ª).
   The two sections are physically adjacent in the PDF â€” always identify which
   section a number belongs to by its section header (×’ vs ×“), not its magnitude.
6. If the track name contains "××¡×œ×•×œ" and is followed by a % figure in the
   same box/cell under the ×“ header, that % is the ×ª×©×•××” â€” copy it EXACTLY.

If a table cannot be found in the document, return an empty array [] for that key.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: extract specific section from raw text by header keyword
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Section header keywords (in Hebrew) that mark the START of each table section
_SECTION_HEADERS = [
    "×ª×©×œ×•××™× ×¦×¤×•×™×™×",       # ×
    "×ª× ×•×¢×•×ª ×‘×§×¨×Ÿ",           # ×‘
    "×“××™ × ×™×”×•×œ",             # ×’
    "××¡×œ×•×œ×™ ×”×©×§×¢×”",          # ×“
    "×¤×™×¨×•×˜ ×”×¤×§×“×•×ª",          # ×”
    "×¤×¨×˜×™ ×¡×•×›×Ÿ",             # ×• â€” used only as an end-boundary
]

def extract_section(raw_text: str, section_keyword: str) -> str:
    """
    Return only the portion of raw_text that starts at the line containing
    section_keyword and ends at the first line containing any other section header.
    Falls back to the full raw_text if the keyword is not found.
    """
    lines = raw_text.splitlines()
    start_idx = None

    for i, line in enumerate(lines):
        if section_keyword in line:
            start_idx = i
            break

    if start_idx is None:
        return raw_text  # keyword not found â€” return full text as fallback

    # Find the end: first subsequent line that contains a DIFFERENT section header
    end_idx = len(lines)
    for i in range(start_idx + 1, len(lines)):
        for header in _SECTION_HEADERS:
            if header != section_keyword and header in lines[i]:
                end_idx = i
                break
        if end_idx != len(lines):
            break

    return "\n".join(lines[start_idx:end_idx])


def call_openai(raw_text: str, openai_client: openai.OpenAI) -> dict:
    """Send raw PDF text to GPT-4o and return parsed JSON dict.
    
    For table_d specifically, we extract only the text under the
    '××¡×œ×•×œ×™ ×”×©×§×¢×”' section header â€” eliminating any chance of
    confusing returns (×“) with management fees (×’).
    """
    user_message = (
        "Here is the raw text extracted from the pension PDF.\n"
        "Extract tables a, b, c, and e according to your instructions.\n"
        "NOTE: table_d will be extracted separately by a coordinate-based algorithm â€” "
        "you still need to return a table_d key in your JSON but it can be an empty array.\n\n"
        f"{raw_text[:120_000]}"
    )

    response = openai_client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_message},
        ],
        timeout=120,
    )
    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except json.JSONDecodeError as exc:
        st.error(f"JSON parse error from GPT-4o response: {exc}")
        st.text_area("Raw GPT-4o output (debug)", content, height=300)
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: robust number cleaner
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clean_num(value) -> float | None:
    """
    Convert an extracted string to a float.

    Handles:
    - Comma-separated thousands  (e.g. "1,234.56")
    - Israeli trailing minus     (e.g. "500-" or "500â€“")
    - Leading minus / en-dash    (e.g. "-500" or "â€“500")
    - Parenthesised negatives    (e.g. "(500)")
    - Junk strings               (None, "nan", "-", ".", "", whitespace)
    """
    if value is None:
        return None
    s = str(value).strip()

    # Reject obvious non-numbers
    if s in ("", "nan", "-", "â€“", ".", "N/A", "n/a"):
        return None

    # Remove thousands separators (commas)
    s = s.replace(",", "")

    # Parenthesised negative: (500) â†’ -500
    if s.startswith("(") and s.endswith(")"):
        s = "-" + s[1:-1]

    # Trailing minus / en-dash: 500- or 500â€“ â†’ -500
    if re.search(r"[\-â€“]$", s):
        s = "-" + re.sub(r"[\-â€“]$", "", s)

    # Replace leading en-dash with proper minus
    s = s.replace("â€“", "-")

    # Remove any stray non-numeric characters except . and leading -
    s = re.sub(r"[^\d.\-]", "", s)

    if not s or s in ("-", "."):
        return None

    try:
        return float(s)
    except ValueError:
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Table E â€“ "Shift Fix" heuristic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fix_table_e_shifts(rows: list[dict]) -> list[dict]:
    """
    Hebrew RTL PDFs often shift numeric columns left or right.
    Heuristic: the maximum value among (employee, employer, severance, total)
    is ALWAYS the Total (×¡×”"×›) column.  Re-assign accordingly.

    Logic assumptions (standard Israeli pension structure):
        total  â‰ˆ  employee + employer + severance
        total  >  employee, employer, severance individually

    If only one numeric value is found in a row, it is treated as total.
    """
    fixed = []
    for row in rows:
        month    = row.get("month")
        salary   = clean_num(row.get("salary"))
        employee = clean_num(row.get("employee"))
        employer = clean_num(row.get("employer"))
        severance = clean_num(row.get("severance"))
        total    = clean_num(row.get("total"))

        numeric_vals = [v for v in [employee, employer, severance, total] if v is not None]

        if not numeric_vals:
            # Nothing to fix
            fixed.append({
                "month": month,
                "salary": salary,
                "employee": employee,
                "employer": employer,
                "severance": severance,
                "total": total,
            })
            continue

        # The maximum value is logically the total
        max_val = max(numeric_vals)

        # If the current "total" field is already the max, no shift needed
        if total == max_val:
            fixed.append({
                "month": month,
                "salary": salary,
                "employee": employee,
                "employer": employer,
                "severance": severance,
                "total": total,
            })
            continue

        # Shift detected: find which field holds max_val and reassign
        # Collect all four slots in extraction order [employee, employer, severance, total]
        raw_slots = [
            clean_num(row.get("employee")),
            clean_num(row.get("employer")),
            clean_num(row.get("severance")),
            clean_num(row.get("total")),
        ]

        # Identify position of max
        max_idx = None
        for i, v in enumerate(raw_slots):
            if v is not None and v == max_val:
                max_idx = i
                break

        if max_idx is None:
            # Can't determine shift, keep as-is
            fixed.append({
                "month": month,
                "salary": salary,
                "employee": employee,
                "employer": employer,
                "severance": severance,
                "total": total,
            })
            continue

        # Rotate the list so that max_val lands at index 3 (total slot)
        shift = 3 - max_idx
        rotated = raw_slots[-shift:] + raw_slots[:-shift] if shift else raw_slots

        fixed.append({
            "month": month,
            "salary": salary,
            "employee": rotated[0],
            "employer": rotated[1],
            "severance": rotated[2],
            "total": rotated[3],
        })

    return fixed


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cross-validation: Table B total deposits vs Table E sum
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_DEPOSIT_KEYWORDS = ["×”×¤×§×“×•×ª", "×”×¤×§×“×”", "deposits", "deposit", "×§×¨×Ÿ", "×›×•×œ×œ"]

def find_total_deposits_table_b(table_b_df: pd.DataFrame) -> float | None:
    """
    Scan table_b for a row whose description contains deposit-related keywords.
    Returns the numeric amount of the first match, or None.
    """
    if table_b_df is None or table_b_df.empty:
        return None
    for _, row in table_b_df.iterrows():
        desc = str(row.get("description", ""))
        if any(kw in desc for kw in _DEPOSIT_KEYWORDS):
            val = clean_num(row.get("amount"))
            if val is not None:
                return val
    return None


def cross_validate(table_b_df: pd.DataFrame, table_e_df: pd.DataFrame):
    """Display a Streamlit success/warning based on deposit cross-validation."""
    b_total = find_total_deposits_table_b(table_b_df)
    if b_total is None:
        st.info("â„¹ï¸ Could not locate a deposit row in Table B for cross-validation.")
        return

    if table_e_df is None or table_e_df.empty or "total" not in table_e_df.columns:
        st.info("â„¹ï¸ Table E is empty â€” skipping cross-validation.")
        return

    e_sum = table_e_df["total"].sum()
    if math.isnan(e_sum):
        st.info("â„¹ï¸ Table E totals contain NaN â€” cross-validation skipped.")
        return

    diff = abs(b_total - e_sum)
    tolerance = max(1.0, abs(b_total) * 0.01)   # 1% tolerance

    if diff <= tolerance:
        st.success(
            f"âœ… Cross-validation PASSED â€” "
            f"Table B deposits: â‚ª{b_total:,.2f} | Table E sum: â‚ª{e_sum:,.2f} | "
            f"Î” = â‚ª{diff:,.2f}"
        )
    else:
        st.warning(
            f"âš ï¸ Cross-validation MISMATCH â€” "
            f"Table B deposits: â‚ª{b_total:,.2f} | Table E sum: â‚ª{e_sum:,.2f} | "
            f"Î” = â‚ª{diff:,.2f}  (possible column-shift residual or report anomaly)"
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DataFrame builders
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_table_a(rows: list[dict]) -> pd.DataFrame:
    df = pd.DataFrame(rows, columns=["description", "amount"])
    df["amount"] = df["amount"].apply(clean_num)
    return df

def build_table_b(rows: list[dict]) -> pd.DataFrame:
    df = pd.DataFrame(rows, columns=["description", "amount"])
    df["amount"] = df["amount"].apply(clean_num)
    return df

def build_table_c(rows: list[dict]) -> pd.DataFrame:
    df = pd.DataFrame(rows, columns=["description", "percentage"])
    df["percentage"] = df["percentage"].apply(clean_num)
    return df

def extract_table_d_by_coordinates(pdf_bytes: bytes) -> list[dict]:
    """
    ×—×™×œ×•×¥ ×˜×‘×œ×” ×“' ×œ×¤×™ ×§×•××•×¨×“×™× ×˜×•×ª X,Y ×©×œ ××™×œ×•×ª ×˜×§×¡×˜ (PyMuPDF "words" mode).

    ×œ××” ×œ× regex ×¢×œ ×˜×§×¡×˜ ×’×•×œ××™:
      PDF ×¢×‘×¨×™ RTL ×××–×’ ×¢××•×“×•×ª ×œ×©×•×¨×” ××—×ª â€” "××¡×œ×•×œ ×›×œ×œ ×¤× ×¡×™×”  0.17%"
      ×”×•×¤×š ×œ-"1.0××¡×œ×•×œ ×›×œ×œ ×¤× ×¡×™×” ×œ×‘× ×™ 0 5 ×•××˜×”" ×œ×œ× ×¡×™××Ÿ ××—×•×–.

    ×”×¤×ª×¨×•×Ÿ: page.get_text("words") ××—×–×™×¨ ×›×œ ××™×œ×” ×¢× (x0,y0,x1,y1).
    × ×§×‘×¥ ××™×œ×™× ×œ×©×•×¨×•×ª ×œ×¤×™ y0, ×•×‘×›×œ ×©×•×¨×” ×©××›×™×œ×” "××¡×œ×•×œ" × ×—×¤×© ×˜×•×§×Ÿ ××¡×¤×¨×™.
    """
    rows = []
    track_kw   = "××¡×œ×•×œ"
    section_kw = "××¡×œ×•×œ×™ ×”×©×§×¢×”"
    skip_kw    = ("×”×©×§×¢×”", "×ª×©×•××•×ª")
    end_kws    = ("×¤×™×¨×•×˜ ×”×¤×§×“×•×ª", "×¤×¨×˜×™ ×¡×•×›×Ÿ", "×ª× ×•×¢×•×ª ×‘×§×¨×Ÿ")
    Y_TOL      = 4   # ×¤×™×§×¡×œ×™× â€” ×¡×£ ×œ××™×—×•×“ ××™×œ×™× ×œ××•×ª×” ×©×•×¨×”

    num_re = re.compile(r"^-?\d+[.,]\d+%?$")

    try:
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page in doc:
                page_text = page.get_text("text")
                if section_kw not in page_text:
                    continue

                words = page.get_text("words")  # (x0,y0,x1,y1,word,block,line,word_no)

                # ××¦× y ×©×œ ×ª×—×™×œ×ª ×•×¡×•×£ ×¡×¢×™×£ ×“'
                # ×—×©×•×‘: get_text("words") ××—×–×™×¨ ××™×œ×” ×‘×•×“×“×ª ×‘-w[4] â€” ×œ× ×‘×™×˜×•×™ ×©×œ×.
                # ×œ×›×Ÿ ××—×¤×©×™× "××¡×œ×•×œ×™" ×•-"×”×©×§×¢×”" ×›××™×œ×™× × ×¤×¨×“×•×ª ×‘×©×•×¨×” ×§×¨×•×‘×”.
                start_y, end_y = None, None

                # ×‘× ×” ××™×œ×•×Ÿ y -> ×¨×©×™××ª ××™×œ×™× ×œ××™×ª×•×¨ ×‘×™×˜×•×™×™× ××¨×•×‘×™ ××™×œ×™×
                y_to_words: dict[float, list[str]] = {}
                for w in words:
                    y_r = round(w[1], 0)
                    y_to_words.setdefault(y_r, []).append(w[4])

                for y_r, wtokens in sorted(y_to_words.items()):
                    line_str = " ".join(wtokens)
                    # ×ª×—×™×œ×ª ×¡×¢×™×£ ×“': ×©×•×¨×” ×©××›×™×œ×” "××¡×œ×•×œ×™" ×•"×”×©×§×¢×”"
                    if start_y is None and "××¡×œ×•×œ×™" in line_str and "×”×©×§×¢×”" in line_str:
                        start_y = y_r
                        continue
                    # ×¡×•×£ ×¡×¢×™×£ ×“': ×©×•×¨×” ×©××›×™×œ×” ××—×ª ×××™×œ×•×ª ×”×¡×™×•×
                    if start_y is not None:
                        for ek in end_kws:
                            ek_words = ek.split()
                            if all(ew in line_str for ew in ek_words):
                                if end_y is None or y_r < end_y:
                                    end_y = y_r
                                break

                if start_y is None:
                    # Fallback: ×× ×œ× × ××¦××” ×›×•×ª×¨×ª â€” ×—×¤×© ×™×©×™×¨×•×ª ××™×œ×•×ª "××¡×œ×•×œ" ×‘×›×œ ×”×¢××•×“
                    for w in words:
                        if "××¡×œ×•×œ" in w[4] and not any(sk in w[4] for sk in ("×”×©×§×¢×”","×ª×©×•××•×ª")):
                            start_y = w[1] - 5
                            break
                if start_y is None:
                    continue

                # ×¡× ×Ÿ ××™×œ×™× ×œ×¡×¢×™×£ ×“' ×‘×œ×‘×“
                sec_words = [
                    w for w in words
                    if w[1] >= start_y and (end_y is None or w[1] < end_y)
                ]

                # ×§×‘×¥ ××™×œ×™× ×œ×©×•×¨×•×ª ×œ×¤×™ y0
                lines: dict[float, list] = {}
                for w in sec_words:
                    y = round(w[1], 0)
                    matched = next((k for k in lines if abs(k - y) <= Y_TOL), None)
                    key = matched if matched is not None else y
                    lines.setdefault(key, []).append(w)

                # ×¢×‘×•×¨ ×›×œ ×©×•×¨×” ×××•×™× ×ª â€” ××¦× ×©×•×¨×•×ª ××¡×œ×•×œ
                for y_key in sorted(lines):
                    tokens = [w[4] for w in sorted(lines[y_key], key=lambda w: w[0])]
                    full   = " ".join(tokens)

                    if track_kw not in full:
                        continue
                    if any(sk in full for sk in skip_kw):
                        continue  # ×©×•×¨×ª ×›×•×ª×¨×ª

                    # ×—×œ×¥: ×˜×•×§× ×™× ××¡×¤×¨×™×™× = ××—×•×–, ×”×©××¨ = ×©× ××¡×œ×•×œ
                    # PyMuPDF ×œ×¤×¢××™× ××¤×¨×™×“ "0.17" ×•-"%" ×œ×©× ×™ ×˜×•×§× ×™× × ×¤×¨×“×™×
                    pct_tokens  = []
                    name_tokens = []
                    ti = 0
                    while ti < len(tokens):
                        tok = tokens[ti]
                        clean = tok.replace(",", ".").rstrip("%")
                        is_num = bool(re.match(r"^-?\d+[.,]\d+$", clean))
                        if is_num:
                            pct_tokens.append(clean)
                            # ×“×œ×’ ×¢×œ "%" ×©××’×™×¢ ×‘×˜×•×§×Ÿ × ×¤×¨×“ ××™×“ ××—×¨×™ ×”××¡×¤×¨
                            if ti + 1 < len(tokens) and tokens[ti + 1].strip() == "%":
                                ti += 1
                        elif tok.strip() == "%":
                            pass  # % ×‘×•×“×“ ×©×›×‘×¨ ×˜×•×¤×œ
                        else:
                            name_tokens.append(tok)
                        ti += 1

                    percentage = pct_tokens[0] if pct_tokens else None

                    # ×× ×œ× × ××¦× ××—×•×– â€” ×—×¤×© ×‘×©×•×¨×•×ª ×”×§×¨×•×‘×•×ª (y ×’×“×•×œ ×™×•×ª×¨)
                    if percentage is None:
                        sorted_ys = sorted(lines.keys())
                        try:
                            cur_i = sorted_ys.index(y_key)
                        except ValueError:
                            cur_i = -1
                        for ny in sorted_ys[cur_i + 1: cur_i + 5]:
                            next_toks = [w[4] for w in sorted(lines[ny], key=lambda w: w[0])]
                            for tok in next_toks:
                                clean = tok.replace(",", ".").rstrip("%")
                                if num_re.match(tok) or re.match(r"^-?\d+[.,]\d+$", clean):
                                    percentage = clean
                                    break
                            if percentage:
                                break

                    track_name = " ".join(t for t in name_tokens if t.strip()).strip()
                    if track_name:
                        rows.append({
                            "track_name": track_name,
                            "return_percentage": percentage,
                        })

    except Exception as exc:
        st.warning(f"×©×’×™××” ×‘×—×™×œ×•×¥ ×˜×‘×œ×” ×“' ×œ×¤×™ ×§×•××•×¨×“×™× ×˜×•×ª: {exc}")

    return rows


def build_table_d(rows: list[dict]) -> pd.DataFrame:
    df = pd.DataFrame(rows, columns=["track_name", "return_percentage"])
    df["return_percentage"] = df["return_percentage"].apply(clean_num)
    return df


def warn_table_d_sanity(table_d_df: pd.DataFrame, table_c_df: pd.DataFrame):
    """
    ×‘×“×™×§×ª ×©×¤×™×•×ª ×œ×˜×‘×œ×” ×“ â€” ××‘×•×¡×¡×ª ×¢×œ ×›×œ×œ ×—×•×§×™:
    ×“××™ × ×™×”×•×œ ××—×™×¡×›×•×Ÿ ××•×’×‘×œ×™× ×‘×—×•×§ ×œ-0.5% ××§×¡×™××•×.
    ×œ×›×Ÿ ×× ×¢×¨×š ×‘×˜×‘×œ×” ×’ (×“××™ × ×™×”×•×œ ××—×™×¡×›×•×Ÿ) ×¢×•×œ×” ×¢×œ 0.5% â€” ×›× ×¨××” ×©×—×•×œ×¦×” ×ª×©×•××” ×‘×˜×¢×•×ª.
    ×‘× ×•×¡×£: ×× ×¢×¨×š ×‘×˜×‘×œ×” ×“ ×–×”×” ×œ××—×“ ××”×¢×¨×›×™× ×‘×˜×‘×œ×” ×’ â€” ×›× ×¨××” ×©××•×ª×• ××¡×¤×¨ ×”×•×¢×ª×§ ××”×¡×¢×™×£ ×”×œ× × ×›×•×Ÿ.
    """
    # ×‘×“×™×§×” 1: ×“××™ × ×™×”×•×œ ××—×™×¡×›×•×Ÿ ×‘×˜×‘×œ×” ×’ ×œ× ×™×›×•×œ×™× ×œ×¢×œ×•×ª ×¢×œ 0.5%
    if table_c_df is not None and not table_c_df.empty and "percentage" in table_c_df.columns:
        for _, row in table_c_df.iterrows():
            val = row.get("percentage")
            if val is None or (isinstance(val, float) and math.isnan(val)):
                continue
            desc = str(row.get("description", "")).lower()
            if "×—×™×¡×›×•×Ÿ" in desc and float(val) > 0.5:
                st.warning(
                    f"âš ï¸ **×‘×“×™×§×ª ×©×¤×™×•×ª â€” ×˜×‘×œ×” ×’:** ×“××™ × ×™×”×•×œ ××—×™×¡×›×•×Ÿ **{val}%** ×¢×•×œ×™× ×¢×œ "
                    f"×”××§×¡×™××•× ×”×—×•×§×™ ×©×œ 0.5%. ×™×™×ª×›×Ÿ ×©×—×•×œ×¦×” ×ª×©×•××” (×˜×‘×œ×” ×“) ×‘××§×•× ×“××™ × ×™×”×•×œ. "
                    f"×× × ×‘×“×•×§ ××•×œ ×”-PDF ×”××§×•×¨×™."
                )

    # ×‘×“×™×§×” 2: ×¢×¨×š ×‘×˜×‘×œ×” ×“ ×–×”×” ×œ×¢×¨×š ×‘×˜×‘×œ×” ×’ â€” ×¡×™××Ÿ ××–×”×¨×” ×œ×‘×œ×‘×•×œ ×‘×™×Ÿ ×”×¡×¢×™×¤×™×
    if table_d_df is None or table_d_df.empty or "return_percentage" not in table_d_df.columns:
        return
    if table_c_df is None or table_c_df.empty or "percentage" not in table_c_df.columns:
        return

    c_values = set(
        round(float(v), 4)
        for v in table_c_df["percentage"].dropna()
    )

    for _, row in table_d_df.iterrows():
        val = row.get("return_percentage")
        if val is None or (isinstance(val, float) and math.isnan(val)):
            continue
        if round(float(val), 4) in c_values:
            st.warning(
                f"âš ï¸ **×‘×“×™×§×ª ×©×¤×™×•×ª â€” ×˜×‘×œ×” ×“:** ×”×ª×©×•××” **{val}%** ×¢×‘×•×¨ ××¡×œ×•×œ "
                f'"{row.get("track_name", "")}" ×–×”×” ×œ××—×“ ××¢×¨×›×™ ×“××™ ×”× ×™×”×•×œ ×‘×˜×‘×œ×” ×’. '
                f"×™×™×ª×›×Ÿ ×‘×œ×‘×•×œ ×‘×™×Ÿ ×¡×¢×™×£ ×’ ×œ×¡×¢×™×£ ×“. ×× × ×‘×“×•×§ ××•×œ ×”-PDF ×”××§×•×¨×™."
            )

def build_table_e(rows: list[dict]) -> pd.DataFrame:
    fixed = fix_table_e_shifts(rows)
    df = pd.DataFrame(fixed, columns=["month", "salary", "employee", "employer", "severance", "total"])
    for col in ["salary", "employee", "employer", "severance", "total"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Display helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TABLE_META = {
    "table_a": {
        "title": "Table A â€” ×ª×©×œ×•××™× ×¦×¤×•×™×™× (Expected Payments)",
        "icon": "ğŸ’°",
        "float_cols": ["amount"],
        "fmt": "{:,.2f}",
    },
    "table_b": {
        "title": "Table B â€” ×ª× ×•×¢×•×ª ×‘×§×¨×Ÿ (Account Movements)",
        "icon": "ğŸ”„",
        "float_cols": ["amount"],
        "fmt": "{:,.2f}",
    },
    "table_c": {
        "title": "Table C â€” ×“××™ × ×™×”×•×œ ×•×”×•×¦××•×ª (Management Fees)",
        "icon": "ğŸ“‹",
        "float_cols": ["percentage"],
        "fmt": "{:.4f}%",
    },
    "table_d": {
        "title": "Table D â€” ××¡×œ×•×œ×™ ×”×©×§×¢×” ×•×ª×©×•××•×ª (Investment Tracks & Returns)",
        "icon": "ğŸ“ˆ",
        "float_cols": ["return_percentage"],
        "fmt": "{:.4f}%",
    },
    "table_e": {
        "title": "Table E â€” ×¤×™×¨×•×˜ ×”×¤×§×“×•×ª (Monthly Deposit Details)",
        "icon": "ğŸ—‚ï¸",
        "float_cols": ["salary", "employee", "employer", "severance", "total"],
        "fmt": "{:,.2f}",
    },
}

def display_table(key: str, df: pd.DataFrame):
    meta = TABLE_META[key]
    st.subheader(f"{meta['icon']} {meta['title']}")

    if df.empty:
        st.info("No data found for this table in the report.")
        return

    # Build a styled copy for display (keeps underlying df clean)
    display_df = df.copy()
    for col in meta["float_cols"]:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(
                lambda x: meta["fmt"].format(x) if pd.notna(x) else ""
            )

    st.dataframe(display_df, use_container_width=True, hide_index=True)
    st.caption(f"Rows: {len(df)}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main app flow
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

uploaded_file = st.file_uploader(
    "ğŸ“‚ Upload Pension PDF Report",
    type=["pdf"],
    help="Supports reports from Migdal, Altshuler Shaham, Clal, Meitav, More.",
)

if uploaded_file:
    pdf_bytes = uploaded_file.read()

    # â”€â”€ Step 1: Extract raw text â”€â”€
    with st.spinner("ğŸ“„ Extracting text from PDF with PyMuPDFâ€¦"):
        try:
            raw_text = extract_pdf_text(pdf_bytes)
        except Exception:
            st.stop()

    with st.expander("ğŸ” Raw extracted text (debug)", expanded=False):
        st.text_area("Raw PDF Text", raw_text[:8000] + ("\nâ€¦[truncated]" if len(raw_text) > 8000 else ""),
                     height=300, label_visibility="collapsed")

    # â”€â”€ Step 2: GPT-4o structuring â”€â”€
    client = openai.OpenAI(api_key=api_key)

    with st.spinner("ğŸ¤– Sending to GPT-4o for structured extractionâ€¦"):
        try:
            extracted: dict = call_openai(raw_text, client)
        except Exception:
            st.stop()

    with st.expander("ğŸ“Œ ×§×˜×¢ '××¡×œ×•×œ×™ ×”×©×§×¢×”' ××”×˜×§×¡×˜ ×”×’×•×œ××™ (debug)", expanded=False):
        _d_preview = extract_section(raw_text, "××¡×œ×•×œ×™ ×”×©×§×¢×”")
        st.caption("×”×˜×§×¡×˜ ×”×’×•×œ××™ ×©×œ ×¡×¢×™×£ ×“' â€” ×©×™××• ×œ×‘ ×©×”××¡×¤×¨×™× ×¢×œ×•×œ×™× ×œ×”×™×•×ª ××‘×•×œ×’× ×™× ×‘×’×œ×œ RTL. ×œ×›×Ÿ ××©×ª××©×™× ×‘×§×•××•×¨×“×™× ×˜×•×ª X,Y ×•×œ× ×‘×˜×§×¡×˜ ×”×–×”.")
        st.text(_d_preview if _d_preview != raw_text else "âš ï¸ ×”×›×•×ª×¨×ª '××¡×œ×•×œ×™ ×”×©×§×¢×”' ×œ× × ××¦××”")

    with st.expander("ğŸ› ï¸ Raw JSON from GPT-4o (debug)", expanded=False):
        st.json(extracted)

    # â”€â”€ Step 3: Build DataFrames â”€â”€
    builders = {
        "table_a": build_table_a,
        "table_b": build_table_b,
        "table_c": build_table_c,
        "table_e": build_table_e,
    }

    dfs: dict[str, pd.DataFrame] = {}
    for key, builder in builders.items():
        rows = extracted.get(key, [])
        try:
            dfs[key] = builder(rows) if rows else pd.DataFrame()
        except Exception as exc:
            st.warning(f"Could not build {key}: {exc}")
            dfs[key] = pd.DataFrame()

    # â”€â”€ Table D: ×—×™×œ×•×¥ ×œ×¤×™ ×§×•××•×¨×“×™× ×˜×•×ª X,Y â€” ×œ× GPT, ×œ× Regex ×¢×œ ×˜×§×¡×˜ ×’×•×œ××™ â”€â”€
    coord_rows_d = extract_table_d_by_coordinates(pdf_bytes)

    with st.expander("ğŸ”¬ Debug ×˜×‘×œ×” ×“' â€” ×ª×•×¦××•×ª ×—×™×œ×•×¥ ×§×•××•×¨×“×™× ×˜×•×ª", expanded=True):
        if coord_rows_d:
            st.success(f"× ××¦××• {len(coord_rows_d)} ×©×•×¨×•×ª")
            st.json(coord_rows_d)
        else:
            st.error("×œ× × ××¦××• ×©×•×¨×•×ª â€” ×‘×“×•×§ ××ª ×”-debug ×©×œ ×”×˜×§×¡×˜ ×”×’×•×œ××™ ×œ××˜×”")

    if coord_rows_d:
        dfs["table_d"] = build_table_d(coord_rows_d)
        st.success(f"âœ… ×˜×‘×œ×” ×“' ×—×•×œ×¦×” ×œ×¤×™ ×§×•××•×¨×“×™× ×˜×•×ª ({len(coord_rows_d)} ××¡×œ×•×œ×™×)")
    else:
        # fallback: GPT-4o ×× ×”×—×™×œ×•×¥ ×”×’×™××•××˜×¨×™ × ×›×©×œ
        gpt_rows_d = extracted.get("table_d", [])
        dfs["table_d"] = build_table_d(gpt_rows_d) if gpt_rows_d else pd.DataFrame()
        st.warning("âš ï¸ ×—×™×œ×•×¥ ×œ×¤×™ ×§×•××•×¨×“×™× ×˜×•×ª ×œ× ××¦× ××¡×œ×•×œ×™× â€” × ×¢×©×” ×©×™××•×© ×‘×ª×•×¦××ª GPT-4o ×›-fallback")

    # â”€â”€ Step 4: Cross-validation â”€â”€
    st.markdown("---")
    st.subheader("ğŸ” Cross-Validation: Table B â†” Table E")
    cross_validate(dfs.get("table_b"), dfs.get("table_e"))

    # â”€â”€ Step 5: Display all tables â”€â”€
    st.markdown("---")
    st.header("ğŸ“Š Extracted Tables")

    for key in ["table_a", "table_b", "table_c", "table_d", "table_e"]:
        display_table(key, dfs[key])
        if key == "table_d":
            warn_table_d_sanity(dfs.get("table_d"), dfs.get("table_c"))
        st.markdown("---")

    # â”€â”€ Step 6: Download as Excel â”€â”€
    with st.spinner("Preparing Excel exportâ€¦"):
        excel_buffer = io.BytesIO()
        try:
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                sheet_names = {
                    "table_a": "A_Expected_Payments",
                    "table_b": "B_Account_Movements",
                    "table_c": "C_Management_Fees",
                    "table_d": "D_Investment_Tracks",
                    "table_e": "E_Deposit_Details",
                }
                for key, sheet in sheet_names.items():
                    df = dfs.get(key, pd.DataFrame())
                    if not df.empty:
                        df.to_excel(writer, sheet_name=sheet, index=False)
            excel_buffer.seek(0)
        except Exception as exc:
            st.warning(f"Excel export failed: {exc}")
            excel_buffer = None

    if excel_buffer:
        st.download_button(
            label="â¬‡ï¸ Download all tables as Excel",
            data=excel_buffer,
            file_name=f"pension_report_{uploaded_file.name.replace('.pdf', '')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
else:
    st.info("ğŸ‘† Upload a pension PDF report and enter your API key to get started.")
